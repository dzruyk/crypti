Описание интепретатора
======================

Основной программой является Crypti интерпретатор,
который производит запуск скриптов или команд, введённых в 
интерактивной среде программирования (REPL).

Процесс интерпретации разбит на несколько стадий:
- Лексический анализ
- Синтаксический анализ
- Построение абстрактного синтаксического дерева
- Обход и выполнение конструкций в узлах дерева

Стадии перечислены в порядке выполнения. Каждая стадия будет описана ниже.


Лексический анализ
------------------

Введение
~~~~~~~~
Токены - базовые элементы лексического анализа. Лексический анализатор
представляет переданный исходный код как поток токенов. Лексический анализатор
вызывается синтаксическим анализатором и при за каждый вызов возвращает следующий один токен
из исходного кода.

Токен - структура, определяющая один логический элемент,
в ней хранится тип и опционально значения токена.
Например:

Если лексический анализатор найдёт последовательность символов
"this is string" он выделит её в отдельный токен TOK_STRING, где значением токена
будет строка "this is string"

или последовательность 42
будет воспринята как TOK_NUM, где значением токена будет 42.

Реализация
~~~~~~~~~~

В крипти токен определяется следующей структурой.

struct lex_item {
	tok_t id;
	union {
		int num;
		char *name;
		char *str;
	};
};

Где
id - уникальный идентификатор токена.
Полный список идентификаторов можно посмотреть в lex.h.
union { ... } объединение доступных значений токена
num - если токен - число (TOK_NUM)
name - если токен - идентификатор (TOK_ID)
str - если токен - строка
=========================================================================================
write me for octet string
=========================================================================================

Пример:
Если в исходном коде встретилось выражение:
a += 42 + 2 * 2
то лексический анализатор разложит его на соответствующие токены (в порядке поступления)
(TOK_ID, a) 
(TOK_PLUS_AS)
(TOK_NUM, 42)
(TOK_PLUS)
(TOK_NUM, 2)
(TOK_MUL)
(TOK_NUM, 2)

API функции, осуществляющей лексический анализ представлено ниже:

tok_t
get_next_token();

Функция считывает символы из текущего открытого файла (может быть stdin)
и заполняет структуру lex_item значениями считанного токена.

Проще всего описать работу лексического анализатора с помощью регулярных выражений.
Регулярные выражения которые будут использованы для описания:

*
+
[set]

Числа (TOK_NUM):
[0-9]+

alpha_	[a-zA-Z_]

TOK_ID	alpha [alpha | digit]

Операции
assign		->	=
arith_op	->	+ - * / 
bitwise_op	->	>> << | & ^
rel_op		->	< <= >= > == !=
logic_op	->	&& || !
assign_with_op	->	[arith_op | bitwise_op | rel_op]{1} assign

Среди множества идентификаторов есть зарезервированные слова, 
Ключевые слова
~~~~~~~~~~~~~~

Синтаксический анализ
~~~~~~~~~~~~~~~~~~~~~

Построение синтаксического дерева
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Обход и выполнение конструкций в узлах дерева
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


